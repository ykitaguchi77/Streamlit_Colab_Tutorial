{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_webapp.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Streamlit_Colab_Tutorial/blob/main/section_5/MobileNet_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kW_qXJVTjic"
      },
      "source": [
        "# 画像認識アプリ\n",
        "MobileNetV3を用いた画像認識"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●ライブラリのインストール\n",
        "Streamlit、およびアプリの動作の確認に使用する「ngrok」をインストールします。"
      ],
      "metadata": {
        "id": "vRJCuxALcgkb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pbqipzj3nCy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ee6b04-ab86-47c6-e704-09e5edf0c7af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.9 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 28.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 42.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 51.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 544 kB/s \n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit==1.7.0 --quiet\n",
        "!pip install pyngrok==4.1.1 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit、およびngrokをインポートしておきます。  \n",
        "エラーが発生する場合は、「ランタイム」→「ランタイムを再起動」によりランタイムを再起動し、再びコードセルを上から順に実行しましょう。"
      ],
      "metadata": {
        "id": "husUkYy5dhZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "OsHcq-kaDwIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3a083f-a4f7-4377-fbce-ddd800fb89df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "2022-12-12 06:06:27.145 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●「モデル」を扱うファイル\n",
        "画像認識の訓練済みモデルを読み込み、予測を行うコードを「model.py」に書き込みます。  "
      ],
      "metadata": {
        "id": "KoBcfQYBTUSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imagenet_classes.txtを作成\n",
        "!pip install shap --quiet\n",
        "import shap\n",
        "import json\n",
        "\n",
        "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
        "with open(shap.datasets.cache(url)) as file:\n",
        "    class_names = [v[1] for v in json.load(file).values()]\n",
        "\n",
        "with open(\"imagenet_classes.txt\", \"w\") as outfile:\n",
        "    outfile.write(\"\\n\".join(str(item) for item in class_names))\n",
        "     "
      ],
      "metadata": {
        "id": "XRb6ns4A8Ra5",
        "outputId": "35188d0e-f8e5-4273-8127-062db6611ca2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 575 kB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "動作確認"
      ],
      "metadata": {
        "id": "ULnExVWcA_Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download sample image\n",
        "!wget https://www.lamborghini.com/sites/it-en/files/DAM/lamborghini/facelift_2019/model_detail/menu/09_09/menu_asterion.png -O car.png --quiet"
      ],
      "metadata": {
        "id": "FBrfP0J_9xhA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "\n",
        "net = timm.create_model(model_name= \"mobilenetv3_large_100\", pretrained=True)  # 訓練済みのモデルを読み込み\n",
        "with open(\"imagenet_classes.txt\") as f:  # ラベルの読み込み\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "def predict(img):\n",
        "    # 以下の設定はこちらを参考に設定: https://pytorch.org/hub/pytorch_vision_resnet/\n",
        "    transform = transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(\n",
        "                                        mean=[0.485, 0.456, 0.406],\n",
        "                                        std=[0.229, 0.224, 0.225]\n",
        "                                        )\n",
        "                                    ])\n",
        "\n",
        "    # モデルへの入力\n",
        "    img = transform(img)\n",
        "    x = torch.unsqueeze(img, 0)  # バッチ対応\n",
        "\n",
        "    # 予測\n",
        "    net.eval()\n",
        "    y = net(x)\n",
        "\n",
        "    # 結果を返す\n",
        "    y_prob = torch.nn.functional.softmax(torch.squeeze(y))  # 確率で表す\n",
        "    sorted_prob, sorted_indices = torch.sort(y_prob, descending=True)  # 降順にソート\n",
        "    return [(classes[idx], prob.item()) for idx, prob in zip(sorted_indices, sorted_prob)]\n",
        "\n",
        "img = Image.open(\"/content/car.png\").convert('RGB')\n",
        "predict(img)"
      ],
      "metadata": {
        "id": "eHnQlhzm8XfH",
        "outputId": "5f877b09-532c-4fa7-9936-d6ebe22b4b8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models.helpers:Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_large_100_ra-f55367f5.pth)\n",
            "2022-12-12 06:26:18.648 INFO    timm.models.helpers: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_large_100_ra-f55367f5.pth)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKDxia8C_NKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "# 以下を「model.py」に書き込み\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "\n",
        "net = timm.create_model(model_name= \"mobilenetv3_large_100\", pretrained=True)  # 訓練済みのモデルを読み込み\n",
        "with open(\"imagenet_classes.txt\") as f:  # ラベルの読み込み\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "def predict(img):\n",
        "    # 以下の設定はこちらを参考に設定: https://pytorch.org/hub/pytorch_vision_resnet/\n",
        "    transform = transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(\n",
        "                                        mean=[0.485, 0.456, 0.406],\n",
        "                                        std=[0.229, 0.224, 0.225]\n",
        "                                        )\n",
        "                                    ])\n",
        "\n",
        "    # モデルへの入力\n",
        "    img = transform(img)\n",
        "    x = torch.unsqueeze(img, 0)  # バッチ対応\n",
        "\n",
        "    # 予測\n",
        "    net.eval()\n",
        "    y = net(x)\n",
        "\n",
        "    # 結果を返す\n",
        "    y_prob = torch.nn.functional.softmax(torch.squeeze(y))  # 確率で表す\n",
        "    sorted_prob, sorted_indices = torch.sort(y_prob, descending=True)  # 降順にソート\n",
        "    return [(classes[idx], prob.item()) for idx, prob in zip(sorted_indices, sorted_prob)]"
      ],
      "metadata": {
        "id": "nmZpJOe9p6GF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9873a6-2b72-4756-e71c-45945e0aadf5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●アプリのコード\n",
        "画像認識アプリのコードを、「app.py」に書き込みます。  \n",
        "ローカルからアップロード、もしくはWebカメラで撮影した画像ファイルに、何が映っているのかを判定します。  \n",
        "なお、Webカメラはngrokが発行したURLではセキュリティ上動作しないので、今回は動作を確認できません。"
      ],
      "metadata": {
        "id": "5fOtVgU5duPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# 以下を「app.py」に書き込み\n",
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from model import predict\n",
        "\n",
        "st.set_option(\"deprecation.showfileUploaderEncoding\", False)\n",
        "\n",
        "st.sidebar.title(\"画像認識アプリ\")\n",
        "st.sidebar.write(\"ResNetを使って何の画像かを判定します。\")\n",
        "\n",
        "st.sidebar.write(\"\")\n",
        "\n",
        "img_source = st.sidebar.radio(\"画像のソースを選択してください。\",\n",
        "                              (\"画像をアップロード\", \"カメラで撮影\"))\n",
        "if img_source == \"画像をアップロード\":\n",
        "    img_file = st.sidebar.file_uploader(\"画像を選択してください。\", type=[\"png\", \"jpg\"])\n",
        "elif img_source == \"カメラで撮影\":\n",
        "    img_file = st.camera_input(\"カメラで撮影\")\n",
        "\n",
        "if img_file is not None:\n",
        "    with st.spinner(\"推定中...\"):\n",
        "        img = Image.open(img_file).convert('RGB')\n",
        "        st.image(img, caption=\"対象の画像\", width=480)\n",
        "        st.write(\"\")\n",
        "\n",
        "        # 予測\n",
        "        results = predict(img)\n",
        "\n",
        "        # 結果の表示\n",
        "        st.subheader(\"判定結果\")\n",
        "        n_top = 5  # 確率が高い順に5位まで返す\n",
        "        for result in results[:n_top]:\n",
        "            st.write(str(round(result[1]*100, 2)) + \"%の確率で\" + result[0] + \"です。\")\n",
        "\n",
        "        # 円グラフの表示\n",
        "        pie_labels = [result[0] for result in results[:n_top]]\n",
        "        pie_labels.append(\"others\")\n",
        "        pie_probs = [result[1] for result in results[:n_top]]\n",
        "        pie_probs.append(sum([result[1] for result in results[n_top:]]))\n",
        "        fig, ax = plt.subplots()\n",
        "        wedgeprops={\"width\":0.3, \"edgecolor\":\"white\"}\n",
        "        textprops = {\"fontsize\":6}\n",
        "        ax.pie(pie_probs, labels=pie_labels, counterclock=False, startangle=90,\n",
        "               textprops=textprops, autopct=\"%.2f\", wedgeprops=wedgeprops)  # 円グラフ\n",
        "        st.pyplot(fig)"
      ],
      "metadata": {
        "id": "Ntj_BU3bnJli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b6ee98-bcc0-46d5-dc00-6cfbcdad4967"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●Authtokenの設定\n",
        "ngrokで接続するために必要な「Authtoken」を設定します。  \n",
        "以下のコードの、  \n",
        "`!ngrok authtoken YourAuthtoken`  \n",
        "における  \n",
        "`YourAuthtoken`の箇所を、自分のAuthtokenに置き換えます。  \n",
        "Authtokenは、ngrokのサイトに登録すれば取得することができます。  \n",
        "https://ngrok.com/\n"
      ],
      "metadata": {
        "id": "j03EsJaHh4KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2IlpU0zV5qehnqjSE2YLp6giXID_2eseJA59RpbZBH7hdWPQ5"
      ],
      "metadata": {
        "id": "mTfmORj2Dn7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250428d5-b0ba-4f87-deb1-76e9eb7a2a22"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●アプリの起動と動作確認\n",
        "streamlitの`run`コマンドでアプリを起動します。\n"
      ],
      "metadata": {
        "id": "CnobL05MkjB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/dev/null&  # 「&>/dev/null&」により、出力を非表示にしてバックグランドジョブとして実行"
      ],
      "metadata": {
        "id": "W0jXlMXWK0vi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ngrokのプロセスを終了した上で、新たにポートを指定して接続します。  \n",
        "接続の結果、urlを取得できます。  \n",
        "ngrokの無料プランでは同時に1つのプロセスしか動かせないので、エラーが発生した場合は「ランタイム」→「セッションの管理」で不要なGoogle Colabのセッションを修了しましょう。  "
      ],
      "metadata": {
        "id": "W5RLCJ7Sl2x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()  # プロセスの修了\n",
        "url = ngrok.connect(port=\"8501\")  # 接続"
      ],
      "metadata": {
        "id": "v23ymsdLK3x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a76d98-b6af-4f4a-d36b-06c05550197f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process:Killing ngrok process: 478\n",
            "2022-12-12 06:34:21.711 INFO    pyngrok.process: Killing ngrok process: 478\n",
            "INFO:pyngrok.process:ngrok process starting: 532\n",
            "2022-12-12 06:34:21.751 INFO    pyngrok.process: ngrok process starting: 532\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:21+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "\n",
            "2022-12-12 06:34:21.772 INFO    pyngrok.process: t=2022-12-12T06:34:21+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:21+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.ngrok2/ngrok.yml\n",
            "\n",
            "2022-12-12 06:34:21.782 INFO    pyngrok.process: t=2022-12-12T06:34:21+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.ngrok2/ngrok.yml\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:21+0000 lvl=info msg=\"open config file\" path=/root/.ngrok2/ngrok.yml err=nil\n",
            "\n",
            "2022-12-12 06:34:21.794 INFO    pyngrok.process: t=2022-12-12T06:34:21+0000 lvl=info msg=\"open config file\" path=/root/.ngrok2/ngrok.yml err=nil\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:21+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040\n",
            "\n",
            "2022-12-12 06:34:21.805 INFO    pyngrok.process: t=2022-12-12T06:34:21+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "\n",
            "2022-12-12 06:34:22.017 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=\"client session established\" obj=csess id=c6fdc9cbb7c8\n",
            "\n",
            "2022-12-12 06:34:22.028 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=\"client session established\" obj=csess id=c6fdc9cbb7c8\n",
            "\n",
            "INFO:pyngrok.process:ngrok process has started: http://127.0.0.1:4040\n",
            "2022-12-12 06:34:22.043 INFO    pyngrok.process: ngrok process has started: http://127.0.0.1:4040\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=start pg=/api/tunnels id=47a104d3d6715236\n",
            "\n",
            "2022-12-12 06:34:22.063 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=start pg=/api/tunnels id=47a104d3d6715236\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=end pg=/api/tunnels id=47a104d3d6715236 status=200 dur=402.092µs\n",
            "\n",
            "2022-12-12 06:34:22.072 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=end pg=/api/tunnels id=47a104d3d6715236 status=200 dur=402.092µs\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=start pg=/api/tunnels id=8b10b7d2dc9f153c\n",
            "\n",
            "2022-12-12 06:34:22.080 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=start pg=/api/tunnels id=8b10b7d2dc9f153c\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=end pg=/api/tunnels id=8b10b7d2dc9f153c status=200 dur=176.943µs\n",
            "\n",
            "2022-12-12 06:34:22.084 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=end pg=/api/tunnels id=8b10b7d2dc9f153c status=200 dur=176.943µs\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=start pg=/api/tunnels id=38c3d32ce732ae84\n",
            "\n",
            "2022-12-12 06:34:22.088 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=start pg=/api/tunnels id=38c3d32ce732ae84\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=\"http-8501-a8a6be9d-1045-4bd6-ac56-afdeff12ed9f (http)\" addr=http://localhost:8501 url=http://38b4-104-196-66-242.ngrok.io\n",
            "\n",
            "2022-12-12 06:34:22.157 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=\"http-8501-a8a6be9d-1045-4bd6-ac56-afdeff12ed9f (http)\" addr=http://localhost:8501 url=http://38b4-104-196-66-242.ngrok.io\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-8501-a8a6be9d-1045-4bd6-ac56-afdeff12ed9f addr=http://localhost:8501 url=https://38b4-104-196-66-242.ngrok.io\n",
            "\n",
            "2022-12-12 06:34:22.163 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-8501-a8a6be9d-1045-4bd6-ac56-afdeff12ed9f addr=http://localhost:8501 url=https://38b4-104-196-66-242.ngrok.io\n",
            "\n",
            "INFO:pyngrok.process:t=2022-12-12T06:34:22+0000 lvl=info msg=end pg=/api/tunnels id=38c3d32ce732ae84 status=201 dur=91.296279ms\n",
            "\n",
            "2022-12-12 06:34:22.168 INFO    pyngrok.process: t=2022-12-12T06:34:22+0000 lvl=info msg=end pg=/api/tunnels id=38c3d32ce732ae84 status=201 dur=91.296279ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "urlを表示し、リンク先でアプリが動作することを確認します。"
      ],
      "metadata": {
        "id": "NZ0O_pNan57t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(url)"
      ],
      "metadata": {
        "id": "MIY7ositLAXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e94bdd-39bf-41f5-a7bd-5fa53d0c71a9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://38b4-104-196-66-242.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●requirements.txtの作成\n",
        "Streamlit Cloudのサーバー上でアプリを動かすために、「requirements.txt」を作成する必要があります。  \n",
        "このファイルでは、必要なライブラリのバージョンを指定します。  \n"
      ],
      "metadata": {
        "id": "CCdXdIEWqWM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは、アプリでimportするライブラリのバージョンを確認します。"
      ],
      "metadata": {
        "id": "9foNw_ipq9Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit\n",
        "import torch\n",
        "import torchvision\n",
        "import PIL\n",
        "import matplotlib\n",
        "\n",
        "print(\"streamlit==\" + streamlit.__version__)\n",
        "print(\"torch==\" + torch.__version__)\n",
        "print(\"torchvision==\" + torchvision.__version__)\n",
        "print(\"Pillow==\" + PIL.__version__)\n",
        "print(\"matplotlib==\" + matplotlib.__version__)"
      ],
      "metadata": {
        "id": "wzvY6S9qrCkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013559c8-a6af-4156-f794-31d934ff9616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "streamlit==1.7.0\n",
            "torch==1.13.0+cu116\n",
            "torchvision==0.14.0+cu116\n",
            "Pillow==7.1.2\n",
            "matplotlib==3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記を参考に、各ライブラリの望ましいバージョンを記述しrequirements.txtに保存します。"
      ],
      "metadata": {
        "id": "oZ-YlfM8rt76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"requirements.txt\", \"w\") as w:\n",
        "    w.write(\"streamlit==1.8.1\\n\")  # Streamlit Cloud上で動作が確認できたバージョン\n",
        "    w.write(\"torch==1.10.0\\n\")  # Cuda対応は要らないのでcu111は記述しない\n",
        "    w.write(\"torchvision==0.11.1\\n\")  # Cuda対応は要らないのでcu111は記述しない\n",
        "    w.write(\"Pillow==7.1.2\\n\")\n",
        "    w.write(\"matplotlib==3.2.2\\n\")"
      ],
      "metadata": {
        "id": "0h-58Ai2OO63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下の作成されたファイルをダウンロードして、GitHubのレポジトリにアップしましょう。\n",
        "* app.py\n",
        "* model.py\n",
        "* requirements.txt"
      ],
      "metadata": {
        "id": "pVNwH5XOtAt-"
      }
    }
  ]
}